{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "    <h1>Exercise 9.8</h1>\n",
    "    <p>This problem involves the <code>OJ</code> data set which is part of the <code>ISLR</code> package.</p>\n",
    "    <ol>\n",
    "        <li>Create a training set containing a random sample of 800 observations, and a test set containing the remaining observations.</li>\n",
    "        <li>Fit a support vector classifier to the training data using $\\mathrm{cost}=0.01$, with $\\mathrm{Purchase}$ as the response and the other variables as predictors. Use the <code>summary()</code> function to produce summary statistics, and describe the results obtained.</li>\n",
    "        <li>What are the training and test error rates?</li>\n",
    "        <li>Use the <code>tune()</code> function to select an optimal $\\mathrm{cost}$. Consider values in the range 0.01 to 10.</li>\n",
    "        <li>Compute the training and test error rates using this new value for $\\mathrm{cost}$.</li>\n",
    "        <li>Repeat parts 2 through 5 using a support vector machine with a radial kernel. Use the default value for $\\mathrm{gamma}$.</li>\n",
    "        <li>Repeat parts 2 through 5 using a support vector machine with a polynomial kernel. Set $\\mathrm{degree}=2$.</li>\n",
    "        <li>Overall, which approach seems to give the best results on this data?</li>\n",
    "    </ol>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:26:57.961070Z",
     "start_time": "2020-03-19T18:26:57.439554Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# https://stackoverflow.com/questions/34398054/ipython-notebook-cell-multiple-outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.compose import ColumnTransformer  # https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:26:57.979933Z",
     "start_time": "2020-03-19T18:26:57.962425Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Purchase</th>\n",
       "      <th>WeekofPurchase</th>\n",
       "      <th>StoreID</th>\n",
       "      <th>PriceCH</th>\n",
       "      <th>PriceMM</th>\n",
       "      <th>DiscCH</th>\n",
       "      <th>DiscMM</th>\n",
       "      <th>SpecialCH</th>\n",
       "      <th>SpecialMM</th>\n",
       "      <th>LoyalCH</th>\n",
       "      <th>SalePriceMM</th>\n",
       "      <th>SalePriceCH</th>\n",
       "      <th>PriceDiff</th>\n",
       "      <th>Store7</th>\n",
       "      <th>PctDiscMM</th>\n",
       "      <th>PctDiscCH</th>\n",
       "      <th>ListPriceDiff</th>\n",
       "      <th>STORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CH</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.24</td>\n",
       "      <td>No</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CH</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.75</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>No</td>\n",
       "      <td>0.150754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CH</td>\n",
       "      <td>245</td>\n",
       "      <td>1</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>2.09</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.40</td>\n",
       "      <td>No</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091398</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MM</td>\n",
       "      <td>227</td>\n",
       "      <td>1</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>No</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CH</td>\n",
       "      <td>228</td>\n",
       "      <td>7</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.956535</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Purchase  WeekofPurchase  StoreID  PriceCH  PriceMM  DiscCH  DiscMM  \\\n",
       "0       CH             237        1     1.75     1.99    0.00     0.0   \n",
       "1       CH             239        1     1.75     1.99    0.00     0.3   \n",
       "2       CH             245        1     1.86     2.09    0.17     0.0   \n",
       "3       MM             227        1     1.69     1.69    0.00     0.0   \n",
       "4       CH             228        7     1.69     1.69    0.00     0.0   \n",
       "\n",
       "   SpecialCH  SpecialMM   LoyalCH  SalePriceMM  SalePriceCH  PriceDiff Store7  \\\n",
       "0          0          0  0.500000         1.99         1.75       0.24     No   \n",
       "1          0          1  0.600000         1.69         1.75      -0.06     No   \n",
       "2          0          0  0.680000         2.09         1.69       0.40     No   \n",
       "3          0          0  0.400000         1.69         1.69       0.00     No   \n",
       "4          0          0  0.956535         1.69         1.69       0.00    Yes   \n",
       "\n",
       "   PctDiscMM  PctDiscCH  ListPriceDiff  STORE  \n",
       "0   0.000000   0.000000           0.24      1  \n",
       "1   0.150754   0.000000           0.24      1  \n",
       "2   0.000000   0.091398           0.23      1  \n",
       "3   0.000000   0.000000           0.00      1  \n",
       "4   0.000000   0.000000           0.00      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../DataSets/OJ/OJ.csv\")\n",
    "df.head()\n",
    "\n",
    "df_y = df[['Purchase']]\n",
    "df_x = df.drop('Purchase', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:36:36.568590Z",
     "start_time": "2020-03-17T21:36:36.557532Z"
    }
   },
   "source": [
    "<h3>Exercise 9.8.1</h3>\n",
    "<blockquote>\n",
    "    <i>Create a training set containing a random sample of 800 observations, and a test set containing the remaining observations.</i>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:26:58.033563Z",
     "start_time": "2020-03-19T18:26:57.981662Z"
    }
   },
   "outputs": [],
   "source": [
    "df_x_train, df_x_test, df_y_train, df_y_test = train_test_split(df_x, df_y, train_size=800, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exercise 9.8.2</h3>\n",
    "<blockquote>\n",
    "    <i>Fit a support vector classifier to the training data using $\\mathrm{cost}=0.01$, with $\\mathrm{Purchase}$ as the response and the other variables as predictors. Use the <code>summary()</code> function to produce summary statistics, and describe the results obtained.</i>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:26:58.150898Z",
     "start_time": "2020-03-19T18:26:58.035263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['StoreID', 'SpecialCH', 'SpecialMM', 'Store7', 'STORE']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('preprocessor',\n",
       "   ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "                     transformer_weights=None,\n",
       "                     transformers=[('quant',\n",
       "                                    Pipeline(memory=None,\n",
       "                                             steps=[('scaler',\n",
       "                                                     StandardScaler(copy=True,\n",
       "                                                                    with_mean=True,\n",
       "                                                                    with_std=True))],\n",
       "                                             verbose=False),\n",
       "                                    ['WeekofPurchase', 'PriceCH', 'PriceMM',\n",
       "                                     'DiscCH', 'DiscMM', 'LoyalCH', 'SalePriceMM',\n",
       "                                     'SalePriceCH', 'PriceDiff', 'PctDiscMM',\n",
       "                                     'PctDiscCH', 'ListPriceDiff']),\n",
       "                                   ('cat',\n",
       "                                    Pipeline(memory=None,\n",
       "                                             steps=[('transformer',\n",
       "                                                     OneHotEncoder(categories='auto',\n",
       "                                                                   drop=None,\n",
       "                                                                   dtype=<class 'numpy.float64'>,\n",
       "                                                                   handle_unknown='error',\n",
       "                                                                   sparse=True))],\n",
       "                                             verbose=False),\n",
       "                                    ['StoreID', 'SpecialCH', 'SpecialMM', 'Store7',\n",
       "                                     'STORE'])],\n",
       "                     verbose=False)),\n",
       "  ('linear_svc',\n",
       "   SVC(C=0.1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "       decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "       max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "       tol=0.001, verbose=False))],\n",
       " 'verbose': False,\n",
       " 'preprocessor': ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "                   transformer_weights=None,\n",
       "                   transformers=[('quant',\n",
       "                                  Pipeline(memory=None,\n",
       "                                           steps=[('scaler',\n",
       "                                                   StandardScaler(copy=True,\n",
       "                                                                  with_mean=True,\n",
       "                                                                  with_std=True))],\n",
       "                                           verbose=False),\n",
       "                                  ['WeekofPurchase', 'PriceCH', 'PriceMM',\n",
       "                                   'DiscCH', 'DiscMM', 'LoyalCH', 'SalePriceMM',\n",
       "                                   'SalePriceCH', 'PriceDiff', 'PctDiscMM',\n",
       "                                   'PctDiscCH', 'ListPriceDiff']),\n",
       "                                 ('cat',\n",
       "                                  Pipeline(memory=None,\n",
       "                                           steps=[('transformer',\n",
       "                                                   OneHotEncoder(categories='auto',\n",
       "                                                                 drop=None,\n",
       "                                                                 dtype=<class 'numpy.float64'>,\n",
       "                                                                 handle_unknown='error',\n",
       "                                                                 sparse=True))],\n",
       "                                           verbose=False),\n",
       "                                  ['StoreID', 'SpecialCH', 'SpecialMM', 'Store7',\n",
       "                                   'STORE'])],\n",
       "                   verbose=False),\n",
       " 'linear_svc': SVC(C=0.1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "     max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "     tol=0.001, verbose=False),\n",
       " 'preprocessor__n_jobs': None,\n",
       " 'preprocessor__remainder': 'drop',\n",
       " 'preprocessor__sparse_threshold': 0.3,\n",
       " 'preprocessor__transformer_weights': None,\n",
       " 'preprocessor__transformers': [('quant', Pipeline(memory=None,\n",
       "            steps=[('scaler',\n",
       "                    StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       "            verbose=False), ['WeekofPurchase',\n",
       "    'PriceCH',\n",
       "    'PriceMM',\n",
       "    'DiscCH',\n",
       "    'DiscMM',\n",
       "    'LoyalCH',\n",
       "    'SalePriceMM',\n",
       "    'SalePriceCH',\n",
       "    'PriceDiff',\n",
       "    'PctDiscMM',\n",
       "    'PctDiscCH',\n",
       "    'ListPriceDiff']),\n",
       "  ('cat', Pipeline(memory=None,\n",
       "            steps=[('transformer',\n",
       "                    OneHotEncoder(categories='auto', drop=None,\n",
       "                                  dtype=<class 'numpy.float64'>,\n",
       "                                  handle_unknown='error', sparse=True))],\n",
       "            verbose=False), ['StoreID',\n",
       "    'SpecialCH',\n",
       "    'SpecialMM',\n",
       "    'Store7',\n",
       "    'STORE'])],\n",
       " 'preprocessor__verbose': False,\n",
       " 'preprocessor__quant': Pipeline(memory=None,\n",
       "          steps=[('scaler',\n",
       "                  StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       "          verbose=False),\n",
       " 'preprocessor__cat': Pipeline(memory=None,\n",
       "          steps=[('transformer',\n",
       "                  OneHotEncoder(categories='auto', drop=None,\n",
       "                                dtype=<class 'numpy.float64'>,\n",
       "                                handle_unknown='error', sparse=True))],\n",
       "          verbose=False),\n",
       " 'preprocessor__quant__memory': None,\n",
       " 'preprocessor__quant__steps': [('scaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       " 'preprocessor__quant__verbose': False,\n",
       " 'preprocessor__quant__scaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'preprocessor__quant__scaler__copy': True,\n",
       " 'preprocessor__quant__scaler__with_mean': True,\n",
       " 'preprocessor__quant__scaler__with_std': True,\n",
       " 'preprocessor__cat__memory': None,\n",
       " 'preprocessor__cat__steps': [('transformer',\n",
       "   OneHotEncoder(categories='auto', drop=None, dtype=<class 'numpy.float64'>,\n",
       "                 handle_unknown='error', sparse=True))],\n",
       " 'preprocessor__cat__verbose': False,\n",
       " 'preprocessor__cat__transformer': OneHotEncoder(categories='auto', drop=None, dtype=<class 'numpy.float64'>,\n",
       "               handle_unknown='error', sparse=True),\n",
       " 'preprocessor__cat__transformer__categories': 'auto',\n",
       " 'preprocessor__cat__transformer__drop': None,\n",
       " 'preprocessor__cat__transformer__dtype': numpy.float64,\n",
       " 'preprocessor__cat__transformer__handle_unknown': 'error',\n",
       " 'preprocessor__cat__transformer__sparse': True,\n",
       " 'linear_svc__C': 0.1,\n",
       " 'linear_svc__break_ties': False,\n",
       " 'linear_svc__cache_size': 200,\n",
       " 'linear_svc__class_weight': None,\n",
       " 'linear_svc__coef0': 0.0,\n",
       " 'linear_svc__decision_function_shape': 'ovr',\n",
       " 'linear_svc__degree': 3,\n",
       " 'linear_svc__gamma': 'scale',\n",
       " 'linear_svc__kernel': 'linear',\n",
       " 'linear_svc__max_iter': -1,\n",
       " 'linear_svc__probability': False,\n",
       " 'linear_svc__random_state': None,\n",
       " 'linear_svc__shrinking': True,\n",
       " 'linear_svc__tol': 0.001,\n",
       " 'linear_svc__verbose': False}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# support vector classifier\n",
    "# use cross validation to find the optimum value for C\n",
    "columns = df_x.columns\n",
    "\n",
    "quantative_variables = [\n",
    "    'WeekofPurchase', \n",
    "    'PriceCH', \n",
    "    'PriceMM', \n",
    "    'DiscCH', \n",
    "    'DiscMM', \n",
    "    'LoyalCH', \n",
    "    'SalePriceMM', \n",
    "    'SalePriceCH', \n",
    "    'PriceDiff', \n",
    "    'PctDiscMM', \n",
    "    'PctDiscCH', \n",
    "    'ListPriceDiff'\n",
    "]\n",
    "quantative_transformer = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "categorical_variables = [column for column in columns if not column in quantative_variables]\n",
    "categorical_variables\n",
    "categorical_transformer = Pipeline([\n",
    "    ('transformer', OneHotEncoder()),\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('quant', quantative_transformer, quantative_variables),\n",
    "        ('cat', categorical_transformer, categorical_variables)\n",
    "    ]\n",
    ")\n",
    "\n",
    "linear_svm_class = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('linear_svc', SVC(kernel='linear', C=0.1))\n",
    "])\n",
    "_ = linear_svm_class.fit(df_x_train, df_y_train['Purchase'])\n",
    "linear_svm_class.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T21:02:45.017909Z",
     "start_time": "2020-03-18T21:02:45.004281Z"
    }
   },
   "source": [
    "<h3>Exercise 9.8.3</h3>\n",
    "<blockquote>\n",
    "    <i>What are the training and test error rates?</i>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:26:58.234252Z",
     "start_time": "2020-03-19T18:26:58.152427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error = 0.155 %\n",
      "test error = 0.178 %\n"
     ]
    }
   ],
   "source": [
    "print(f'training error = {1 - linear_svm_class.score(df_x_train, df_y_train):.3f} %')\n",
    "print(f'test error = {1 - linear_svm_class.score(df_x_test, df_y_test):.3f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exercise 9.8.4</h3>\n",
    "<blockquote>\n",
    "    <i>Use the <code>tune()</code> function to select an optimal $\\mathrm{cost}$. Consider values in the range 0.01 to 10.</i>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:27:02.820372Z",
     "start_time": "2020-03-19T18:26:58.235543Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validated test error = 0.164 %\n"
     ]
    }
   ],
   "source": [
    "linear_svm_class = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('linear_svc', SVC(kernel='linear'))\n",
    "])\n",
    "\n",
    "param_grid={\n",
    "    'linear_svc__C': np.linspace(0, 10, 101),\n",
    "}\n",
    "\n",
    "grid_search_linear_svm_class = GridSearchCV(linear_svm_class, param_grid=param_grid, n_jobs=-1)\n",
    "# use training set for cross validation, so we use a training set, validation set, and test set\n",
    "_ = grid_search_linear_svm_class.fit(df_x_train, df_y_train['Purchase'])\n",
    "\n",
    "\n",
    "# print(grid_search_linear_svm_class.best_estimator_)\n",
    "print(f'cross-validated test error = {1 - grid_search_linear_svm_class.best_score_:.3f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exercise 9.8.5</h3>\n",
    "<blockquote>\n",
    "    <i>Compute the training and test error rates using this new value for $\\mathrm{cost}$.</i>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:27:02.842062Z",
     "start_time": "2020-03-19T18:27:02.821913Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error = 0.156 %\n",
      "test error = 0.185 %\n"
     ]
    }
   ],
   "source": [
    "print(f'training error = {1 - grid_search_linear_svm_class.best_estimator_.score(df_x_train, df_y_train):.3f} %')\n",
    "print(f'test error = {1 - grid_search_linear_svm_class.best_estimator_.score(df_x_test, df_y_test):.3f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exercise 9.8.6</h3>\n",
    "<blockquote>\n",
    "    <i>Repeat parts 2 through 5 using a support vector machine with a radial kernel. Use the default value for $\\mathrm{gamma}$.</i>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:27:02.947457Z",
     "start_time": "2020-03-19T18:27:02.844364Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('preprocessor',\n",
       "   ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "                     transformer_weights=None,\n",
       "                     transformers=[('quant',\n",
       "                                    Pipeline(memory=None,\n",
       "                                             steps=[('scaler',\n",
       "                                                     StandardScaler(copy=True,\n",
       "                                                                    with_mean=True,\n",
       "                                                                    with_std=True))],\n",
       "                                             verbose=False),\n",
       "                                    ['WeekofPurchase', 'PriceCH', 'PriceMM',\n",
       "                                     'DiscCH', 'DiscMM', 'LoyalCH', 'SalePriceMM',\n",
       "                                     'SalePriceCH', 'PriceDiff', 'PctDiscMM',\n",
       "                                     'PctDiscCH', 'ListPriceDiff']),\n",
       "                                   ('cat',\n",
       "                                    Pipeline(memory=None,\n",
       "                                             steps=[('transformer',\n",
       "                                                     OneHotEncoder(categories='auto',\n",
       "                                                                   drop=None,\n",
       "                                                                   dtype=<class 'numpy.float64'>,\n",
       "                                                                   handle_unknown='error',\n",
       "                                                                   sparse=True))],\n",
       "                                             verbose=False),\n",
       "                                    ['StoreID', 'SpecialCH', 'SpecialMM', 'Store7',\n",
       "                                     'STORE'])],\n",
       "                     verbose=False)),\n",
       "  ('rbf_svc',\n",
       "   SVC(C=0.1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "       decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "       max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "       tol=0.001, verbose=False))],\n",
       " 'verbose': False,\n",
       " 'preprocessor': ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "                   transformer_weights=None,\n",
       "                   transformers=[('quant',\n",
       "                                  Pipeline(memory=None,\n",
       "                                           steps=[('scaler',\n",
       "                                                   StandardScaler(copy=True,\n",
       "                                                                  with_mean=True,\n",
       "                                                                  with_std=True))],\n",
       "                                           verbose=False),\n",
       "                                  ['WeekofPurchase', 'PriceCH', 'PriceMM',\n",
       "                                   'DiscCH', 'DiscMM', 'LoyalCH', 'SalePriceMM',\n",
       "                                   'SalePriceCH', 'PriceDiff', 'PctDiscMM',\n",
       "                                   'PctDiscCH', 'ListPriceDiff']),\n",
       "                                 ('cat',\n",
       "                                  Pipeline(memory=None,\n",
       "                                           steps=[('transformer',\n",
       "                                                   OneHotEncoder(categories='auto',\n",
       "                                                                 drop=None,\n",
       "                                                                 dtype=<class 'numpy.float64'>,\n",
       "                                                                 handle_unknown='error',\n",
       "                                                                 sparse=True))],\n",
       "                                           verbose=False),\n",
       "                                  ['StoreID', 'SpecialCH', 'SpecialMM', 'Store7',\n",
       "                                   'STORE'])],\n",
       "                   verbose=False),\n",
       " 'rbf_svc': SVC(C=0.1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "     max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "     tol=0.001, verbose=False),\n",
       " 'preprocessor__n_jobs': None,\n",
       " 'preprocessor__remainder': 'drop',\n",
       " 'preprocessor__sparse_threshold': 0.3,\n",
       " 'preprocessor__transformer_weights': None,\n",
       " 'preprocessor__transformers': [('quant', Pipeline(memory=None,\n",
       "            steps=[('scaler',\n",
       "                    StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       "            verbose=False), ['WeekofPurchase',\n",
       "    'PriceCH',\n",
       "    'PriceMM',\n",
       "    'DiscCH',\n",
       "    'DiscMM',\n",
       "    'LoyalCH',\n",
       "    'SalePriceMM',\n",
       "    'SalePriceCH',\n",
       "    'PriceDiff',\n",
       "    'PctDiscMM',\n",
       "    'PctDiscCH',\n",
       "    'ListPriceDiff']),\n",
       "  ('cat', Pipeline(memory=None,\n",
       "            steps=[('transformer',\n",
       "                    OneHotEncoder(categories='auto', drop=None,\n",
       "                                  dtype=<class 'numpy.float64'>,\n",
       "                                  handle_unknown='error', sparse=True))],\n",
       "            verbose=False), ['StoreID',\n",
       "    'SpecialCH',\n",
       "    'SpecialMM',\n",
       "    'Store7',\n",
       "    'STORE'])],\n",
       " 'preprocessor__verbose': False,\n",
       " 'preprocessor__quant': Pipeline(memory=None,\n",
       "          steps=[('scaler',\n",
       "                  StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       "          verbose=False),\n",
       " 'preprocessor__cat': Pipeline(memory=None,\n",
       "          steps=[('transformer',\n",
       "                  OneHotEncoder(categories='auto', drop=None,\n",
       "                                dtype=<class 'numpy.float64'>,\n",
       "                                handle_unknown='error', sparse=True))],\n",
       "          verbose=False),\n",
       " 'preprocessor__quant__memory': None,\n",
       " 'preprocessor__quant__steps': [('scaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       " 'preprocessor__quant__verbose': False,\n",
       " 'preprocessor__quant__scaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'preprocessor__quant__scaler__copy': True,\n",
       " 'preprocessor__quant__scaler__with_mean': True,\n",
       " 'preprocessor__quant__scaler__with_std': True,\n",
       " 'preprocessor__cat__memory': None,\n",
       " 'preprocessor__cat__steps': [('transformer',\n",
       "   OneHotEncoder(categories='auto', drop=None, dtype=<class 'numpy.float64'>,\n",
       "                 handle_unknown='error', sparse=True))],\n",
       " 'preprocessor__cat__verbose': False,\n",
       " 'preprocessor__cat__transformer': OneHotEncoder(categories='auto', drop=None, dtype=<class 'numpy.float64'>,\n",
       "               handle_unknown='error', sparse=True),\n",
       " 'preprocessor__cat__transformer__categories': 'auto',\n",
       " 'preprocessor__cat__transformer__drop': None,\n",
       " 'preprocessor__cat__transformer__dtype': numpy.float64,\n",
       " 'preprocessor__cat__transformer__handle_unknown': 'error',\n",
       " 'preprocessor__cat__transformer__sparse': True,\n",
       " 'rbf_svc__C': 0.1,\n",
       " 'rbf_svc__break_ties': False,\n",
       " 'rbf_svc__cache_size': 200,\n",
       " 'rbf_svc__class_weight': None,\n",
       " 'rbf_svc__coef0': 0.0,\n",
       " 'rbf_svc__decision_function_shape': 'ovr',\n",
       " 'rbf_svc__degree': 3,\n",
       " 'rbf_svc__gamma': 'auto',\n",
       " 'rbf_svc__kernel': 'rbf',\n",
       " 'rbf_svc__max_iter': -1,\n",
       " 'rbf_svc__probability': False,\n",
       " 'rbf_svc__random_state': None,\n",
       " 'rbf_svc__shrinking': True,\n",
       " 'rbf_svc__tol': 0.001,\n",
       " 'rbf_svc__verbose': False}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 2\n",
    "rbf_svm_class = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('rbf_svc', SVC(kernel='rbf', C=0.1, gamma='auto'))\n",
    "])\n",
    "_ = rbf_svm_class.fit(df_x_train, df_y_train['Purchase'])\n",
    "rbf_svm_class.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:27:03.151392Z",
     "start_time": "2020-03-19T18:27:02.949097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error = 0.171 %\n",
      "test error = 0.178 %\n"
     ]
    }
   ],
   "source": [
    "# step 3\n",
    "print(f'training error = {1 - rbf_svm_class.score(df_x_train, df_y_train):.3f} %')\n",
    "print(f'test error = {1 - rbf_svm_class.score(df_x_test, df_y_test):.3f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:27:05.396402Z",
     "start_time": "2020-03-19T18:27:03.152940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validated test error = 0.166 %\n"
     ]
    }
   ],
   "source": [
    "# step 4\n",
    "rbf_svm_class = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('rbf_svc', SVC(kernel='rbf', gamma='auto'))\n",
    "])\n",
    "\n",
    "param_grid={\n",
    "    'rbf_svc__C': np.linspace(0, 10, 101),\n",
    "}\n",
    "\n",
    "grid_search_rbf_svm_class = GridSearchCV(rbf_svm_class, param_grid=param_grid, n_jobs=-1)\n",
    "# use training set for cross validation, so we use a training set, validation set, and test set\n",
    "_ = grid_search_rbf_svm_class.fit(df_x_train, df_y_train['Purchase'])\n",
    "\n",
    "\n",
    "# print(grid_search_rbf_svm_class.best_estimator_)\n",
    "print(f'cross-validated test error = {1 - grid_search_rbf_svm_class.best_score_:.3f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:27:05.432052Z",
     "start_time": "2020-03-19T18:27:05.399315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error = 0.145 %\n",
      "test error = 0.189 %\n"
     ]
    }
   ],
   "source": [
    "# step 5\n",
    "print(f'training error = {1 - grid_search_rbf_svm_class.best_estimator_.score(df_x_train, df_y_train):.3f} %')\n",
    "print(f'test error = {1 - grid_search_rbf_svm_class.best_estimator_.score(df_x_test, df_y_test):.3f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exercise 9.8.7</h3>\n",
    "<blockquote>\n",
    "    <i>Repeat parts 2 through 5 using a support vector machine with a polynomial kernel. Set $\\mathrm{degree}=2$.</i>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:27:05.612364Z",
     "start_time": "2020-03-19T18:27:05.433961Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('preprocessor',\n",
       "   ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "                     transformer_weights=None,\n",
       "                     transformers=[('quant',\n",
       "                                    Pipeline(memory=None,\n",
       "                                             steps=[('scaler',\n",
       "                                                     StandardScaler(copy=True,\n",
       "                                                                    with_mean=True,\n",
       "                                                                    with_std=True))],\n",
       "                                             verbose=False),\n",
       "                                    ['WeekofPurchase', 'PriceCH', 'PriceMM',\n",
       "                                     'DiscCH', 'DiscMM', 'LoyalCH', 'SalePriceMM',\n",
       "                                     'SalePriceCH', 'PriceDiff', 'PctDiscMM',\n",
       "                                     'PctDiscCH', 'ListPriceDiff']),\n",
       "                                   ('cat',\n",
       "                                    Pipeline(memory=None,\n",
       "                                             steps=[('transformer',\n",
       "                                                     OneHotEncoder(categories='auto',\n",
       "                                                                   drop=None,\n",
       "                                                                   dtype=<class 'numpy.float64'>,\n",
       "                                                                   handle_unknown='error',\n",
       "                                                                   sparse=True))],\n",
       "                                             verbose=False),\n",
       "                                    ['StoreID', 'SpecialCH', 'SpecialMM', 'Store7',\n",
       "                                     'STORE'])],\n",
       "                     verbose=False)),\n",
       "  ('poly_svc',\n",
       "   SVC(C=0.1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "       decision_function_shape='ovr', degree=2, gamma='scale', kernel='poly',\n",
       "       max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "       tol=0.001, verbose=False))],\n",
       " 'verbose': False,\n",
       " 'preprocessor': ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "                   transformer_weights=None,\n",
       "                   transformers=[('quant',\n",
       "                                  Pipeline(memory=None,\n",
       "                                           steps=[('scaler',\n",
       "                                                   StandardScaler(copy=True,\n",
       "                                                                  with_mean=True,\n",
       "                                                                  with_std=True))],\n",
       "                                           verbose=False),\n",
       "                                  ['WeekofPurchase', 'PriceCH', 'PriceMM',\n",
       "                                   'DiscCH', 'DiscMM', 'LoyalCH', 'SalePriceMM',\n",
       "                                   'SalePriceCH', 'PriceDiff', 'PctDiscMM',\n",
       "                                   'PctDiscCH', 'ListPriceDiff']),\n",
       "                                 ('cat',\n",
       "                                  Pipeline(memory=None,\n",
       "                                           steps=[('transformer',\n",
       "                                                   OneHotEncoder(categories='auto',\n",
       "                                                                 drop=None,\n",
       "                                                                 dtype=<class 'numpy.float64'>,\n",
       "                                                                 handle_unknown='error',\n",
       "                                                                 sparse=True))],\n",
       "                                           verbose=False),\n",
       "                                  ['StoreID', 'SpecialCH', 'SpecialMM', 'Store7',\n",
       "                                   'STORE'])],\n",
       "                   verbose=False),\n",
       " 'poly_svc': SVC(C=0.1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=2, gamma='scale', kernel='poly',\n",
       "     max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "     tol=0.001, verbose=False),\n",
       " 'preprocessor__n_jobs': None,\n",
       " 'preprocessor__remainder': 'drop',\n",
       " 'preprocessor__sparse_threshold': 0.3,\n",
       " 'preprocessor__transformer_weights': None,\n",
       " 'preprocessor__transformers': [('quant', Pipeline(memory=None,\n",
       "            steps=[('scaler',\n",
       "                    StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       "            verbose=False), ['WeekofPurchase',\n",
       "    'PriceCH',\n",
       "    'PriceMM',\n",
       "    'DiscCH',\n",
       "    'DiscMM',\n",
       "    'LoyalCH',\n",
       "    'SalePriceMM',\n",
       "    'SalePriceCH',\n",
       "    'PriceDiff',\n",
       "    'PctDiscMM',\n",
       "    'PctDiscCH',\n",
       "    'ListPriceDiff']),\n",
       "  ('cat', Pipeline(memory=None,\n",
       "            steps=[('transformer',\n",
       "                    OneHotEncoder(categories='auto', drop=None,\n",
       "                                  dtype=<class 'numpy.float64'>,\n",
       "                                  handle_unknown='error', sparse=True))],\n",
       "            verbose=False), ['StoreID',\n",
       "    'SpecialCH',\n",
       "    'SpecialMM',\n",
       "    'Store7',\n",
       "    'STORE'])],\n",
       " 'preprocessor__verbose': False,\n",
       " 'preprocessor__quant': Pipeline(memory=None,\n",
       "          steps=[('scaler',\n",
       "                  StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       "          verbose=False),\n",
       " 'preprocessor__cat': Pipeline(memory=None,\n",
       "          steps=[('transformer',\n",
       "                  OneHotEncoder(categories='auto', drop=None,\n",
       "                                dtype=<class 'numpy.float64'>,\n",
       "                                handle_unknown='error', sparse=True))],\n",
       "          verbose=False),\n",
       " 'preprocessor__quant__memory': None,\n",
       " 'preprocessor__quant__steps': [('scaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       " 'preprocessor__quant__verbose': False,\n",
       " 'preprocessor__quant__scaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'preprocessor__quant__scaler__copy': True,\n",
       " 'preprocessor__quant__scaler__with_mean': True,\n",
       " 'preprocessor__quant__scaler__with_std': True,\n",
       " 'preprocessor__cat__memory': None,\n",
       " 'preprocessor__cat__steps': [('transformer',\n",
       "   OneHotEncoder(categories='auto', drop=None, dtype=<class 'numpy.float64'>,\n",
       "                 handle_unknown='error', sparse=True))],\n",
       " 'preprocessor__cat__verbose': False,\n",
       " 'preprocessor__cat__transformer': OneHotEncoder(categories='auto', drop=None, dtype=<class 'numpy.float64'>,\n",
       "               handle_unknown='error', sparse=True),\n",
       " 'preprocessor__cat__transformer__categories': 'auto',\n",
       " 'preprocessor__cat__transformer__drop': None,\n",
       " 'preprocessor__cat__transformer__dtype': numpy.float64,\n",
       " 'preprocessor__cat__transformer__handle_unknown': 'error',\n",
       " 'preprocessor__cat__transformer__sparse': True,\n",
       " 'poly_svc__C': 0.1,\n",
       " 'poly_svc__break_ties': False,\n",
       " 'poly_svc__cache_size': 200,\n",
       " 'poly_svc__class_weight': None,\n",
       " 'poly_svc__coef0': 0.0,\n",
       " 'poly_svc__decision_function_shape': 'ovr',\n",
       " 'poly_svc__degree': 2,\n",
       " 'poly_svc__gamma': 'scale',\n",
       " 'poly_svc__kernel': 'poly',\n",
       " 'poly_svc__max_iter': -1,\n",
       " 'poly_svc__probability': False,\n",
       " 'poly_svc__random_state': None,\n",
       " 'poly_svc__shrinking': True,\n",
       " 'poly_svc__tol': 0.001,\n",
       " 'poly_svc__verbose': False}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 2\n",
    "poly_svm_class = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('poly_svc', SVC(kernel='poly', C=0.1, degree=2))\n",
    "])\n",
    "_ = poly_svm_class.fit(df_x_train, df_y_train['Purchase'])\n",
    "poly_svm_class.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:27:05.674402Z",
     "start_time": "2020-03-19T18:27:05.613977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error = 0.198 %\n",
      "test error = 0.200 %\n"
     ]
    }
   ],
   "source": [
    "# step 3\n",
    "print(f'training error = {1 - poly_svm_class.score(df_x_train, df_y_train):.3f} %')\n",
    "print(f'test error = {1 - poly_svm_class.score(df_x_test, df_y_test):.3f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:27:08.068908Z",
     "start_time": "2020-03-19T18:27:05.675745Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validated test error = 0.167 %\n"
     ]
    }
   ],
   "source": [
    "# step 4\n",
    "poly_svm_class = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('poly_svc', SVC(kernel='poly', degree=2))\n",
    "])\n",
    "\n",
    "param_grid={\n",
    "    'poly_svc__C': np.linspace(0, 10, 101),\n",
    "}\n",
    "\n",
    "grid_search_poly_svm_class = GridSearchCV(poly_svm_class, param_grid=param_grid, n_jobs=-1)\n",
    "# use training set for cross validation, so we use a training set, validation set, and test set\n",
    "_ = grid_search_poly_svm_class.fit(df_x_train, df_y_train['Purchase'])\n",
    "\n",
    "\n",
    "# print(grid_search_poly_svm_class.best_estimator_)\n",
    "print(f'cross-validated test error = {1 - grid_search_poly_svm_class.best_score_:.3f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:27:08.095137Z",
     "start_time": "2020-03-19T18:27:08.070477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error = 0.137 %\n",
      "test error = 0.200 %\n"
     ]
    }
   ],
   "source": [
    "# step 5\n",
    "print(f'training error = {1 - grid_search_poly_svm_class.best_estimator_.score(df_x_train, df_y_train):.3f} %')\n",
    "print(f'test error = {1 - grid_search_poly_svm_class.best_estimator_.score(df_x_test, df_y_test):.3f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exercise 9.8.8</h3>\n",
    "<blockquote>\n",
    "    <i>Overall, which approach seems to give the best results on this data?</i>\n",
    "</blockquote>\n",
    "\n",
    "<p>We will use the test error to pick our best model, so it seems that the linear kernel gives the best results.</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
