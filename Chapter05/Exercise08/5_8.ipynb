{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "    <h1>Exercise 5.8</h1>\n",
    "    <p>We will now perform cross-validation on a simulated data set.</p>\n",
    "    <ol>\n",
    "        <li>\n",
    "            Generate a simulated data set as follows:<br>\n",
    "<code>> set.seed(1)\n",
    "> y=rnorm(100)\n",
    "> x=rnorm(100)\n",
    "> y=x-2*x^2+rnorm(100)</code> <br>\n",
    "            In this data set, what is $n$ and what is $p$? Write out the model used to generate the data in equation form.\n",
    "        </li>\n",
    "        <li>Create a scatterplot of $X$ against $Y$. Comment on what you find.</li>\n",
    "        <li>\n",
    "            Set a random seed, and then compute the LOOCV errors that\n",
    "result from fitting the following four models using least squares:\n",
    "            <ol>\n",
    "                <li>$Y = \\beta_0 + \\beta_1 X + \\epsilon$</li>\n",
    "                <li>$Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\epsilon$</li>\n",
    "                <li>$Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\beta_3 X^3 + \\epsilon$</li>\n",
    "                <li>$Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\beta_3 X^3 + \\beta_4 X^4 + \\epsilon$</li>\n",
    "            </ol>\n",
    "            Note you may find it helpful to use the <code>data.frame()</code> function to create a single data set containing both $X$ and $Y$.\n",
    "        </li>\n",
    "        <li>Repeat 3 using another random seed, and report your results. Are your results the same as what you got in 3? Why?</li>\n",
    "        <li>Which of the models in 3 had the smallest LOOCV error? Is this what you expected? Explain your answer.</li>\n",
    "        <li>Comment on the statistical significance of the coefficient estimates that results from fitting each of the models in 3 using least squares. Do these results agree with the conclusions drawn based on the cross-validation results?</li>\n",
    "    </ol>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-26T13:19:17.705721Z",
     "start_time": "2020-01-26T13:19:17.161989Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# https://stackoverflow.com/questions/34398054/ipython-notebook-cell-multiple-outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import LeaveOneOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exercise 5.8.1</h3>\n",
    "<blockquote>\n",
    "    <i>Generate a simulated data set as follows:<br>\n",
    "<code>> set.seed(1)\n",
    "> y=rnorm(100)\n",
    "> x=rnorm(100)\n",
    "> y=x-2*x^2+rnorm(100)</code> <br>\n",
    "In this data set, what is $n$ and what is $p$? Write out the model used to generate the data in equation form.</i>\n",
    "</blockquote>\n",
    "\n",
    "<p>For this data set, $n=100$ and $p=2$, and the model is expressed as\n",
    "    $$\n",
    "    y = x - 2x^2 + \\epsilon \\,,\n",
    "    $$\n",
    "where $\\epsilon \\sim \\mathcal{N}(0,\\,1)$.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-26T13:19:17.710601Z",
     "start_time": "2020-01-26T13:19:17.707198Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "n = 100\n",
    "x = np.random.normal(size=n, loc=0, scale=1)\n",
    "y = x - 2*x**2 + np.random.normal(size=n, loc=0, scale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exercise 5.8.2</h3>\n",
    "<blockquote>\n",
    "    <i>Create a scatterplot of $X$ against $Y$. Comment on what you find.</i>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-26T13:19:18.047083Z",
     "start_time": "2020-01-26T13:19:17.712379Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, constrained_layout=True, figsize=(9, 6))\n",
    "_ = ax.scatter(x=x, y=y)\n",
    "_ = ax.set_xlabel('x')\n",
    "_ = ax.set_ylabel('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exercise 5.8.3</h3>\n",
    "<blockquote>\n",
    "    <i>Set a random seed, and then compute the LOOCV errors that\n",
    "result from fitting the following four models using least squares:\n",
    "        <ol>\n",
    "            <li>$Y = \\beta_0 + \\beta_1 X + \\epsilon$</li>\n",
    "            <li>$Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\epsilon$</li>\n",
    "            <li>$Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\beta_3 X^3 + \\epsilon$</li>\n",
    "            <li>$Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\beta_3 X^3 + \\beta_4 X^4 + \\epsilon$</li>\n",
    "        </ol>\n",
    "Note you may find it helpful to use the <code>data.frame()</code> function to create a single data set containing both $X$ and $Y$.</i>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-26T13:19:18.953521Z",
     "start_time": "2020-01-26T13:19:18.048723Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for the polynomial fit of degree 1, the LOOCV estimate is 6.260764331604617'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'for the polynomial fit of degree 2, the LOOCV estimate is 0.9142897072803658'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'for the polynomial fit of degree 3, the LOOCV estimate is 0.9268768781648802'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'for the polynomial fit of degree 4, the LOOCV estimate is 0.8669116865881087'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x = pd.DataFrame({\n",
    "    'x1': x,\n",
    "    'x2': x**2,\n",
    "    'x3': x**3,\n",
    "    'x4': x**4,\n",
    "})\n",
    "df_x.insert(0, 'Intercept', 1)\n",
    "df_y = pd.DataFrame({'y': y})\n",
    "\n",
    "descriptiveColumns = ['Intercept']\n",
    "\n",
    "loocv = LeaveOneOut() # leave-one-out cross-validation\n",
    "\n",
    "for i in range(1, 5):\n",
    "    MSE = 0\n",
    "    poly_degree = 'x' + str(i)\n",
    "    descriptiveColumns += [poly_degree]\n",
    "    for train_index, test_index in loocv.split(df_x):\n",
    "        df_x_train, df_x_test = df_x[descriptiveColumns].iloc[train_index], df_x[descriptiveColumns].iloc[test_index]\n",
    "        df_y_train, df_y_test = df_y.iloc[train_index], df_y.iloc[test_index]\n",
    "\n",
    "        model = sm.OLS(df_y_train, df_x_train)\n",
    "        fitted = model.fit()\n",
    "        Y_pred = fitted.predict(df_x_test.to_numpy())\n",
    "        MSE += (df_y_test.iloc[0, 0] - Y_pred[0])**2\n",
    "\n",
    "    f'for the polynomial fit of degree {i}, the LOOCV estimate is {MSE / n}'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exercise 5.8.4</h3>\n",
    "<blockquote>\n",
    "    <i>Repeat 3 using another random seed, and report your results. Are your results the same as what you got in 3? Why?</i>\n",
    "</blockquote>\n",
    "\n",
    "<p>There is no randomness in the training/validation set, so performing the LOOCV with a different seed will yield the same results.</p>\n",
    "\n",
    "<h3>Exercise 5.8.5</h3>\n",
    "<blockquote>\n",
    "    <i>Which of the models in 3 had the smallest LOOCV error? Is this what you expected? Explain your answer.</i>\n",
    "</blockquote>\n",
    "\n",
    "<p>The polynomial fit of degree 4 resulted in the smallest LOOCV error, which is not what I expected because the true model is a polynomial of degree 2 and so I would have expected that the fit of degree 2 would have results in the smallest LOOCV error. In fact, chaning the seed in cell 2 of this cell to <code>seed = 0</code> will result in the fit of degree 2 to have the smallest LOOCV error. This discrepancy is thus due to the statistical noise, which can be validated by increasing $n$ from $n=100$ to $n=1000$.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-26T13:19:28.225101Z",
     "start_time": "2020-01-26T13:19:18.955030Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for the polynomial fit of degree 1, the LOOCV estimate is 9.112753777466398'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'for the polynomial fit of degree 2, the LOOCV estimate is 1.063343734883582'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'for the polynomial fit of degree 3, the LOOCV estimate is 1.0654540727285113'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'for the polynomial fit of degree 4, the LOOCV estimate is 1.06445720231886'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "n = 1000\n",
    "x = np.random.normal(size=n, loc=0, scale=1)\n",
    "y = x - 2*x**2 + np.random.normal(size=n, loc=0, scale=1)\n",
    "\n",
    "df_x = pd.DataFrame({\n",
    "    'x1': x,\n",
    "    'x2': x**2,\n",
    "    'x3': x**3,\n",
    "    'x4': x**4,\n",
    "})\n",
    "df_x.insert(0, 'Intercept', 1)\n",
    "df_y = pd.DataFrame({'y': y})\n",
    "\n",
    "descriptiveColumns = ['Intercept']\n",
    "\n",
    "loocv = LeaveOneOut() # leave-one-out cross-validation\n",
    "\n",
    "for i in range(1, 5):\n",
    "    MSE = 0\n",
    "    poly_degree = 'x' + str(i)\n",
    "    descriptiveColumns += [poly_degree]\n",
    "    for train_index, test_index in loocv.split(df_x):\n",
    "        df_x_train, df_x_test = df_x[descriptiveColumns].iloc[train_index], df_x[descriptiveColumns].iloc[test_index]\n",
    "        df_y_train, df_y_test = df_y.iloc[train_index], df_y.iloc[test_index]\n",
    "\n",
    "        model = sm.OLS(df_y_train, df_x_train)\n",
    "        fitted = model.fit()\n",
    "        Y_pred = fitted.predict(df_x_test.to_numpy())\n",
    "        MSE += (df_y_test.iloc[0, 0] - Y_pred[0])**2\n",
    "\n",
    "    f'for the polynomial fit of degree {i}, the LOOCV estimate is {MSE / n}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exercise 5.8.6</h3>\n",
    "<blockquote>\n",
    "    <i>Comment on the statistical significance of the coefficient estimates that results from fitting each of the models in 3 using least squares. Do these results agree with the conclusions drawn based on the cross-validation results?</i>\n",
    "</blockquote>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-26T13:19:28.231365Z",
     "start_time": "2020-01-26T13:19:28.226444Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "n = 100\n",
    "x = np.random.normal(size=n, loc=0, scale=1)\n",
    "y = x - 2*x**2 + np.random.normal(size=n, loc=0, scale=1)\n",
    "\n",
    "df_x = pd.DataFrame({\n",
    "    'x1': x,\n",
    "    'x2': x**2,\n",
    "    'x3': x**3,\n",
    "    'x4': x**4,\n",
    "})\n",
    "df_x.insert(0, 'Intercept', 1)\n",
    "df_y = pd.DataFrame({'y': y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-26T13:19:28.358418Z",
     "start_time": "2020-01-26T13:19:28.232708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   9.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 26 Jan 2020</td> <th>  Prob (F-statistic):</th>  <td>0.00209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:19:28</td>     <th>  Log-Likelihood:    </th> <td> -228.87</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   461.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    98</td>      <th>  BIC:               </th> <td>   466.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -1.4131</td> <td>    0.242</td> <td>   -5.849</td> <td> 0.000</td> <td>   -1.893</td> <td>   -0.934</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>        <td>    0.8610</td> <td>    0.272</td> <td>    3.162</td> <td> 0.002</td> <td>    0.321</td> <td>    1.401</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>37.310</td> <th>  Durbin-Watson:     </th> <td>   1.661</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  69.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.554</td> <th>  Prob(JB):          </th> <td>8.01e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.651</td> <th>  Cond. No.          </th> <td>    1.15</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.093\n",
       "Model:                            OLS   Adj. R-squared:                  0.083\n",
       "Method:                 Least Squares   F-statistic:                     9.997\n",
       "Date:                Sun, 26 Jan 2020   Prob (F-statistic):            0.00209\n",
       "Time:                        14:19:28   Log-Likelihood:                -228.87\n",
       "No. Observations:                 100   AIC:                             461.7\n",
       "Df Residuals:                      98   BIC:                             466.9\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -1.4131      0.242     -5.849      0.000      -1.893      -0.934\n",
       "x1             0.8610      0.272      3.162      0.002       0.321       1.401\n",
       "==============================================================================\n",
       "Omnibus:                       37.310   Durbin-Watson:                   1.661\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               69.521\n",
       "Skew:                          -1.554   Prob(JB):                     8.01e-16\n",
       "Kurtosis:                       5.651   Cond. No.                         1.15\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.OLS(df_y, df_x[['Intercept', 'x1']])\n",
    "fitted = model.fit()\n",
    "fitted.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-26T13:19:28.487299Z",
     "start_time": "2020-01-26T13:19:28.362906Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.863</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.860</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   304.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 26 Jan 2020</td> <th>  Prob (F-statistic):</th> <td>1.47e-42</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:19:28</td>     <th>  Log-Likelihood:    </th> <td> -134.42</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   274.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    97</td>      <th>  BIC:               </th> <td>   282.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.1350</td> <td>    0.115</td> <td>    1.169</td> <td> 0.245</td> <td>   -0.094</td> <td>    0.364</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>        <td>    1.0936</td> <td>    0.107</td> <td>   10.229</td> <td> 0.000</td> <td>    0.881</td> <td>    1.306</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>        <td>   -1.9846</td> <td>    0.085</td> <td>  -23.331</td> <td> 0.000</td> <td>   -2.153</td> <td>   -1.816</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.893</td> <th>  Durbin-Watson:     </th> <td>   2.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.640</td> <th>  Jarque-Bera (JB):  </th> <td>   0.552</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.170</td> <th>  Prob(JB):          </th> <td>   0.759</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.132</td> <th>  Cond. No.          </th> <td>    2.10</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.863\n",
       "Model:                            OLS   Adj. R-squared:                  0.860\n",
       "Method:                 Least Squares   F-statistic:                     304.9\n",
       "Date:                Sun, 26 Jan 2020   Prob (F-statistic):           1.47e-42\n",
       "Time:                        14:19:28   Log-Likelihood:                -134.42\n",
       "No. Observations:                 100   AIC:                             274.8\n",
       "Df Residuals:                      97   BIC:                             282.7\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.1350      0.115      1.169      0.245      -0.094       0.364\n",
       "x1             1.0936      0.107     10.229      0.000       0.881       1.306\n",
       "x2            -1.9846      0.085    -23.331      0.000      -2.153      -1.816\n",
       "==============================================================================\n",
       "Omnibus:                        0.893   Durbin-Watson:                   2.152\n",
       "Prob(Omnibus):                  0.640   Jarque-Bera (JB):                0.552\n",
       "Skew:                          -0.170   Prob(JB):                        0.759\n",
       "Kurtosis:                       3.132   Cond. No.                         2.10\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.OLS(df_y, df_x[['Intercept', 'x1', 'x2']])\n",
    "fitted = model.fit()\n",
    "fitted.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-26T13:19:28.574314Z",
     "start_time": "2020-01-26T13:19:28.490924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.865</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.861</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   204.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 26 Jan 2020</td> <th>  Prob (F-statistic):</th> <td>1.40e-41</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:19:28</td>     <th>  Log-Likelihood:    </th> <td> -133.66</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   275.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    96</td>      <th>  BIC:               </th> <td>   285.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.1280</td> <td>    0.115</td> <td>    1.111</td> <td> 0.269</td> <td>   -0.101</td> <td>    0.357</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>        <td>    0.9065</td> <td>    0.187</td> <td>    4.842</td> <td> 0.000</td> <td>    0.535</td> <td>    1.278</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>        <td>   -1.9753</td> <td>    0.085</td> <td>  -23.187</td> <td> 0.000</td> <td>   -2.144</td> <td>   -1.806</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>        <td>    0.0788</td> <td>    0.065</td> <td>    1.216</td> <td> 0.227</td> <td>   -0.050</td> <td>    0.208</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.539</td> <th>  Durbin-Watson:     </th> <td>   2.129</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.463</td> <th>  Jarque-Bera (JB):  </th> <td>   1.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.236</td> <th>  Prob(JB):          </th> <td>   0.583</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.193</td> <th>  Cond. No.          </th> <td>    5.53</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.865\n",
       "Model:                            OLS   Adj. R-squared:                  0.861\n",
       "Method:                 Least Squares   F-statistic:                     204.8\n",
       "Date:                Sun, 26 Jan 2020   Prob (F-statistic):           1.40e-41\n",
       "Time:                        14:19:28   Log-Likelihood:                -133.66\n",
       "No. Observations:                 100   AIC:                             275.3\n",
       "Df Residuals:                      96   BIC:                             285.7\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.1280      0.115      1.111      0.269      -0.101       0.357\n",
       "x1             0.9065      0.187      4.842      0.000       0.535       1.278\n",
       "x2            -1.9753      0.085    -23.187      0.000      -2.144      -1.806\n",
       "x3             0.0788      0.065      1.216      0.227      -0.050       0.208\n",
       "==============================================================================\n",
       "Omnibus:                        1.539   Durbin-Watson:                   2.129\n",
       "Prob(Omnibus):                  0.463   Jarque-Bera (JB):                1.081\n",
       "Skew:                          -0.236   Prob(JB):                        0.583\n",
       "Kurtosis:                       3.193   Cond. No.                         5.53\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.OLS(df_y, df_x[['Intercept', 'x1', 'x2', 'x3']])\n",
    "fitted = model.fit()\n",
    "fitted.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-26T13:19:28.667014Z",
     "start_time": "2020-01-26T13:19:28.578203Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.873</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.867</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   163.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 26 Jan 2020</td> <th>  Prob (F-statistic):</th> <td>1.24e-41</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:19:28</td>     <th>  Log-Likelihood:    </th> <td> -130.63</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   271.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    95</td>      <th>  BIC:               </th> <td>   284.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.3140</td> <td>    0.136</td> <td>    2.311</td> <td> 0.023</td> <td>    0.044</td> <td>    0.584</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>        <td>    0.9127</td> <td>    0.183</td> <td>    4.999</td> <td> 0.000</td> <td>    0.550</td> <td>    1.275</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>        <td>   -2.5445</td> <td>    0.248</td> <td>  -10.264</td> <td> 0.000</td> <td>   -3.037</td> <td>   -2.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>        <td>    0.0992</td> <td>    0.064</td> <td>    1.556</td> <td> 0.123</td> <td>   -0.027</td> <td>    0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>        <td>    0.1394</td> <td>    0.057</td> <td>    2.437</td> <td> 0.017</td> <td>    0.026</td> <td>    0.253</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.537</td> <th>  Durbin-Watson:     </th> <td>   2.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.464</td> <th>  Jarque-Bera (JB):  </th> <td>   1.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.238</td> <th>  Prob(JB):          </th> <td>   0.581</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.184</td> <th>  Cond. No.          </th> <td>    15.9</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.873\n",
       "Model:                            OLS   Adj. R-squared:                  0.867\n",
       "Method:                 Least Squares   F-statistic:                     163.0\n",
       "Date:                Sun, 26 Jan 2020   Prob (F-statistic):           1.24e-41\n",
       "Time:                        14:19:28   Log-Likelihood:                -130.63\n",
       "No. Observations:                 100   AIC:                             271.3\n",
       "Df Residuals:                      95   BIC:                             284.3\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.3140      0.136      2.311      0.023       0.044       0.584\n",
       "x1             0.9127      0.183      4.999      0.000       0.550       1.275\n",
       "x2            -2.5445      0.248    -10.264      0.000      -3.037      -2.052\n",
       "x3             0.0992      0.064      1.556      0.123      -0.027       0.226\n",
       "x4             0.1394      0.057      2.437      0.017       0.026       0.253\n",
       "==============================================================================\n",
       "Omnibus:                        1.537   Durbin-Watson:                   2.100\n",
       "Prob(Omnibus):                  0.464   Jarque-Bera (JB):                1.088\n",
       "Skew:                          -0.238   Prob(JB):                        0.581\n",
       "Kurtosis:                       3.184   Cond. No.                         15.9\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.OLS(df_y, df_x[['Intercept', 'x1', 'x2', 'x3', 'x4']])\n",
    "fitted = model.fit()\n",
    "fitted.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We see that the $p$ values of $\\hat{\\beta_1}$ and $\\hat{\\beta_2}$ indicate a very strong relation, whereas the other coefficients have large $p$ values. This make sense due to the model being used to generate the data.</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
